{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6 + GPU",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Copy of Sentiment_Analysis.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "va0dDcl0Dx7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noAQfbyWD9Qd",
        "colab_type": "text"
      },
      "source": [
        "## Fetch the tweets\n",
        "\n",
        "Load in a collections of tweets. These tweets were downloaded from Twitter's streaming API over a number of hours for any tweets containing the words *happy*, *sad*, *joy*, *anger*, *angry*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49d0fIF9Dx73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"https://github.com/IBMDeveloperUK/ML-For-Everyone/blob/master/20200609-Analysing-Tweet-Sentiment-with-Keras/tweets.csv.gz?raw=true\", compression='gzip')\n",
        "df.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkxaFpNYDx78",
        "colab_type": "code",
        "colab": {},
        "outputId": "8eba821f-51b6-4b48-f3db-be0da4e9e3a3"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Tweet Matched Keywords  \\\n",
              "1  @VanessaMorgan Feeling hopeless, angry and afr...            angry   \n",
              "2                @Byune_hyune happy birthday ya.  ðŸ¤—ðŸ’•            happy   \n",
              "3         @LeaKThompson Happy birthday, Ms Thompson.            happy   \n",
              "4         @KillMyCastaway happy birthday tom holland            happy   \n",
              "5  The way some humans behave to others based on ...              sad   \n",
              "\n",
              "                  Date           User               Source  \\\n",
              "1  2020-05-31 21:53:48    davidsSon85   Twitter for iPhone   \n",
              "2  2020-05-31 21:53:48    PutriRa2721  Twitter for Android   \n",
              "3  2020-05-31 21:53:49   CyberWolf_CC  Twitter for Android   \n",
              "4  2020-05-31 21:53:49  tombaeholland   Twitter for iPhone   \n",
              "5  2020-05-31 21:53:49         djzinc     Tweetbot for iÎŸS   \n",
              "\n",
              "              Tweet ID                                         Tweet URL  \n",
              "1  1267212712121176066  https://twitter.com/statuses/1267212712121176066  \n",
              "2  1267212712204922885  https://twitter.com/statuses/1267212712204922885  \n",
              "3  1267212713119399937  https://twitter.com/statuses/1267212713119399937  \n",
              "4  1267212713387835395  https://twitter.com/statuses/1267212713387835395  \n",
              "5  1267212713958178816  https://twitter.com/statuses/1267212713958178816  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Matched Keywords</th>\n",
              "      <th>Date</th>\n",
              "      <th>User</th>\n",
              "      <th>Source</th>\n",
              "      <th>Tweet ID</th>\n",
              "      <th>Tweet URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@VanessaMorgan Feeling hopeless, angry and afr...</td>\n",
              "      <td>angry</td>\n",
              "      <td>2020-05-31 21:53:48</td>\n",
              "      <td>davidsSon85</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>1267212712121176066</td>\n",
              "      <td>https://twitter.com/statuses/1267212712121176066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@Byune_hyune happy birthday ya.  ðŸ¤—ðŸ’•</td>\n",
              "      <td>happy</td>\n",
              "      <td>2020-05-31 21:53:48</td>\n",
              "      <td>PutriRa2721</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>1267212712204922885</td>\n",
              "      <td>https://twitter.com/statuses/1267212712204922885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@LeaKThompson Happy birthday, Ms Thompson.</td>\n",
              "      <td>happy</td>\n",
              "      <td>2020-05-31 21:53:49</td>\n",
              "      <td>CyberWolf_CC</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>1267212713119399937</td>\n",
              "      <td>https://twitter.com/statuses/1267212713119399937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@KillMyCastaway happy birthday tom holland</td>\n",
              "      <td>happy</td>\n",
              "      <td>2020-05-31 21:53:49</td>\n",
              "      <td>tombaeholland</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>1267212713387835395</td>\n",
              "      <td>https://twitter.com/statuses/1267212713387835395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The way some humans behave to others based on ...</td>\n",
              "      <td>sad</td>\n",
              "      <td>2020-05-31 21:53:49</td>\n",
              "      <td>djzinc</td>\n",
              "      <td>Tweetbot for iÎŸS</td>\n",
              "      <td>1267212713958178816</td>\n",
              "      <td>https://twitter.com/statuses/1267212713958178816</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31Csmia6ERC2",
        "colab_type": "text"
      },
      "source": [
        "## Pre-process the tweets\n",
        "\n",
        "We need to tokenise the tweets, and categorise the tweets into the two classes we will be predicting *joy* and *anger*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4dbTkwNDx8D",
        "colab_type": "code",
        "colab": {},
        "outputId": "93fd2006-7092-47a1-b85f-48b22bf37da1"
      },
      "source": [
        "df2 = pd.DataFrame()\n",
        "tkn  = Tokenizer()\n",
        "\n",
        "df2['tweet'] = df['Tweet']\n",
        "\n",
        "tkn.fit_on_texts(df2['tweet'])\n",
        "vocab_size = len(tkn.word_index) + 1\n",
        "print(vocab_size)\n",
        "\n",
        "df2['tkns'] = tkn.texts_to_sequences(df2['tweet'])\n",
        "\n",
        "joy_re = re.compile(r\"\\b((?<!no )joy|(?<!not )happy|not sad|not angry|no anger)\\b\", re.I)\n",
        "anger_re = re.compile(r\"\\b((?<!not )sad|(?<!not )angry|(?<!no )anger|not happy|no joy)\\b\", re.I)\n",
        "\n",
        "df2['joy'] = df2['tweet'].apply(lambda x: 1 if re.search(joy_re, x) else 0)\n",
        "df2['anger'] = df2['tweet'].apply(lambda x: 1 if re.search(anger_re, x) else 0)\n",
        "\n",
        "\n",
        "df2.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "472607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               tweet  \\\n",
              "1  @VanessaMorgan Feeling hopeless, angry and afr...   \n",
              "2                @Byune_hyune happy birthday ya.  ðŸ¤—ðŸ’•   \n",
              "3         @LeaKThompson Happy birthday, Ms Thompson.   \n",
              "4         @KillMyCastaway happy birthday tom holland   \n",
              "5  The way some humans behave to others based on ...   \n",
              "\n",
              "                                                tkns  joy  anger  \n",
              "1  [13315, 301, 3441, 36, 4, 823, 89, 34, 546, 10...    0      1  \n",
              "2                    [3358, 3359, 1, 16, 251, 14567]    1      0  \n",
              "3                        [11964, 1, 16, 2414, 21397]    1      0  \n",
              "4                          [5357, 1, 16, 1050, 2349]    1      0  \n",
              "5  [3, 136, 106, 1219, 4347, 2, 326, 1605, 35, 70...    0      1  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>tkns</th>\n",
              "      <th>joy</th>\n",
              "      <th>anger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@VanessaMorgan Feeling hopeless, angry and afr...</td>\n",
              "      <td>[13315, 301, 3441, 36, 4, 823, 89, 34, 546, 10...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@Byune_hyune happy birthday ya.  ðŸ¤—ðŸ’•</td>\n",
              "      <td>[3358, 3359, 1, 16, 251, 14567]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@LeaKThompson Happy birthday, Ms Thompson.</td>\n",
              "      <td>[11964, 1, 16, 2414, 21397]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@KillMyCastaway happy birthday tom holland</td>\n",
              "      <td>[5357, 1, 16, 1050, 2349]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The way some humans behave to others based on ...</td>\n",
              "      <td>[3, 136, 106, 1219, 4347, 2, 326, 1605, 35, 70...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE4JcCMqEmAs",
        "colab_type": "text"
      },
      "source": [
        "Calculate the length of each tweet, then calculate the 99% quantile for length and we will use that as the maximum length of the tweets we will process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YECW6qODx8J",
        "colab_type": "code",
        "colab": {},
        "outputId": "dc7ea3df-737a-4e09-e284-0534006dc0cd"
      },
      "source": [
        "df2['len'] = df2['tkns'].apply(lambda x: len(x))\n",
        "df2.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               tweet  \\\n",
              "1  @VanessaMorgan Feeling hopeless, angry and afr...   \n",
              "2                @Byune_hyune happy birthday ya.  ðŸ¤—ðŸ’•   \n",
              "3         @LeaKThompson Happy birthday, Ms Thompson.   \n",
              "4         @KillMyCastaway happy birthday tom holland   \n",
              "5  The way some humans behave to others based on ...   \n",
              "\n",
              "                                                tkns  joy  anger  len  \n",
              "1  [13315, 301, 3441, 36, 4, 823, 89, 34, 546, 10...    0      1   15  \n",
              "2                    [3358, 3359, 1, 16, 251, 14567]    1      0    6  \n",
              "3                        [11964, 1, 16, 2414, 21397]    1      0    5  \n",
              "4                          [5357, 1, 16, 1050, 2349]    1      0    5  \n",
              "5  [3, 136, 106, 1219, 4347, 2, 326, 1605, 35, 70...    0      1   42  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>tkns</th>\n",
              "      <th>joy</th>\n",
              "      <th>anger</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@VanessaMorgan Feeling hopeless, angry and afr...</td>\n",
              "      <td>[13315, 301, 3441, 36, 4, 823, 89, 34, 546, 10...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@Byune_hyune happy birthday ya.  ðŸ¤—ðŸ’•</td>\n",
              "      <td>[3358, 3359, 1, 16, 251, 14567]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@LeaKThompson Happy birthday, Ms Thompson.</td>\n",
              "      <td>[11964, 1, 16, 2414, 21397]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@KillMyCastaway happy birthday tom holland</td>\n",
              "      <td>[5357, 1, 16, 1050, 2349]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The way some humans behave to others based on ...</td>\n",
              "      <td>[3, 136, 106, 1219, 4347, 2, 326, 1605, 35, 70...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfCxskr9Dx8N",
        "colab_type": "code",
        "colab": {},
        "outputId": "62c5cb6d-128e-49a6-a48b-65701fda090c"
      },
      "source": [
        "max_len = int(df2['len'].quantile(0.99))\n",
        "max_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzvA_Hj9E1tS",
        "colab_type": "text"
      },
      "source": [
        "## Pre-trained word vectors\n",
        "\n",
        "We will be using the GloVe pre-trained word vectors from:\n",
        "\n",
        "https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "There is a specific collection collated from Twitter. This is downloadable as a zip file of CSV data. For usage below the 100 vector set has been converted to a python dictionary mapping word to a size (100,) numpy array and then pickled. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46crfZgfDx8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import types\n",
        "import pandas as pd\n",
        "from botocore.client import Config\n",
        "import ibm_boto3\n",
        "\n",
        "def __iter__(self): return 0\n",
        "\n",
        "# @hidden_cell\n",
        "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
        "# You might want to remove those credentials before you share the notebook.\n",
        "client_32ba12f9aedd46c2a5230b8cb8fe2d3f = ibm_boto3.client(service_name='s3',\n",
        "    ibm_api_key_id='<fill in API Key>',\n",
        "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
        "    config=Config(signature_version='oauth'),\n",
        "    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n",
        "\n",
        "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
        "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
        "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
        "# pandas documentation: http://pandas.pydata.org/\n",
        "streaming_body_1 = client_32ba12f9aedd46c2a5230b8cb8fe2d3f.get_object(Bucket='twitchdemos2-donotdelete-pr-8dngl3cqohbrop', Key='glove.pkl')['Body']\n",
        "# add missing __iter__ method, so pandas accepts body as file-like object\n",
        "if not hasattr(streaming_body_1, \"__iter__\"): streaming_body_1.__iter__ = types.MethodType( __iter__, streaming_body_1 ) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC1F4RrmDx8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "embedding_index = pickle.loads(streaming_body_1.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfU88SS4Dx8a",
        "colab_type": "code",
        "colab": {},
        "outputId": "6b59df3a-d0b2-43f0-f2a3-b9a13fc5ae2c"
      },
      "source": [
        "# Test to see we have a vector for a common word, e.g. cat\n",
        "embedding_index['cat']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.38446  , -0.45507  ,  0.45351  ,  0.4301   , -0.050908 ,\n",
              "       -0.26414  ,  0.43253  , -0.3166   ,  0.32214  ,  0.0064333,\n",
              "       -0.47066  ,  0.95335  , -3.2063   ,  0.010913 , -0.27565  ,\n",
              "        1.1732   ,  0.52033  , -0.045973 ,  0.094254 , -0.53846  ,\n",
              "        0.0035668,  0.11934  , -0.17815  , -0.58093  ,  0.65081  ,\n",
              "       -0.48746  , -0.50961  ,  0.42771  , -0.30638  ,  0.32385  ,\n",
              "        0.33687  , -0.1717   , -0.39104  , -0.19038  ,  0.37016  ,\n",
              "       -0.50396  ,  0.041969 , -0.20517  ,  0.3223   ,  0.41217  ,\n",
              "       -0.42191  , -0.26359  , -0.1773   , -0.35658  ,  0.52145  ,\n",
              "        0.57282  ,  0.60204  ,  0.74369  ,  0.33377  , -0.45041  ,\n",
              "        0.015978 , -0.12575  ,  0.29786  , -0.77635  ,  0.23759  ,\n",
              "        0.63821  ,  0.63726  ,  1.0079   ,  0.13714  , -0.031928 ,\n",
              "       -0.21299  ,  0.52348  ,  0.67934  , -0.1427   , -0.64236  ,\n",
              "       -0.47996  , -0.87915  ,  0.17501  ,  0.64517  ,  0.3778   ,\n",
              "        0.53493  , -0.29723  , -0.25206  , -0.757    ,  0.33647  ,\n",
              "        0.053759 , -0.8084   ,  0.22205  ,  0.10799  , -0.68982  ,\n",
              "        1.5073   ,  0.96641  , -0.51839  ,  0.32803  ,  0.11878  ,\n",
              "       -0.72009  ,  0.23227  ,  0.098733 , -0.096396 ,  0.40295  ,\n",
              "       -0.003925 , -0.10405  , -0.15234  ,  0.17573  ,  0.29694  ,\n",
              "        0.14938  ,  0.11754  ,  0.15699  , -0.34272  ,  0.2435   ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvsvck-SFg-s",
        "colab_type": "text"
      },
      "source": [
        "## Create an Embedding Matrix\n",
        "We create an embedding matrix in which we convert the words into the integer token values from the tokenizers word index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXHhB-HTDx8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 100), dtype=np.float32)\n",
        "for word, i in tkn.word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuShmbDODx8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad the documents out to the same length, based on out max length calculated above\n",
        "padded_docs = pad_sequences(df2['tkns'], maxlen=max_len, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o82UKVIUDx8m",
        "colab_type": "code",
        "colab": {},
        "outputId": "0bc4a9c7-8e83-4888-e028-d44d02bd5cb7"
      },
      "source": [
        "labels = df2[['joy', 'anger']].values\n",
        "\n",
        "# inspect a single document to see if it looks reasonable\n",
        "padded_docs[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13315,   301,  3441,    36,     4,   823,    89,    34,   546,\n",
              "          10,   189,    72,    92,     3,   136,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aht41ZxbDx8q",
        "colab_type": "code",
        "colab": {},
        "outputId": "6421e2d8-7531-446b-b880-70d99be839e5"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(472607, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O75nR1NZF5b9",
        "colab_type": "text"
      },
      "source": [
        "## Build and Train our model\n",
        "\n",
        "We build a neural network model with Keras. The model is a two layer LSTM model with dropout layers in between to prevent overfitting.\n",
        "\n",
        "The model is then trained and evaluated on the tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMcWJbLbDx8t",
        "colab_type": "code",
        "colab": {},
        "outputId": "d7655eaf-9482-4e50-933f-231d7799147a"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, CuDNNLSTM as LSTM, Dropout\n",
        "from tensorflow.keras.layers import Embedding, Flatten\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# summarize the model\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 56, 100)           47260700  \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (None, 56, 100)           80800     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 56, 100)           0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_2 (CuDNNLSTM)     (None, 100)               80800     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 47,422,502\n",
            "Trainable params: 161,802\n",
            "Non-trainable params: 47,260,700\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9FKPxfPDx8y",
        "colab_type": "code",
        "colab": {},
        "outputId": "d208d090-00c8-4991-db4e-e5e652ddef9a"
      },
      "source": [
        "keywords = tkn.texts_to_sequences([\"joy happy sad angry anger\"])[0]\n",
        "keywords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[75, 1, 8, 36, 52]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2Rc7eG7Dx82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thresh = int(len(padded_docs) * 0.8)\n",
        "\n",
        "train_X, test_X = padded_docs[:thresh], padded_docs[thresh:]\n",
        "train_y, test_y = labels[:thresh], labels[thresh:]\n",
        "\n",
        "for keyword in keywords:\n",
        "  train_X = np.where(train_X == keyword, 0, train_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2GdGnskDx85",
        "colab_type": "code",
        "colab": {},
        "outputId": "63898957-6221-495d-a19d-b33b6373f055"
      },
      "source": [
        "train_X[-8]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    25,    682,   1141,    657,      7,    258,    601,    119,\n",
              "         1201,      9,   1218,    505,      9,    257,     24,    716,\n",
              "          115,     29,      3,      0,      4,    260,     31,     24,\n",
              "         1356,      3,     72,     62,   2325,    981,   7390,      3,\n",
              "          119,    545,      4,     38,     24,    149,   5908,      3,\n",
              "         1030,   1008,     45,    174,    421, 389067,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdVvObXtDx87",
        "colab_type": "code",
        "colab": {},
        "outputId": "de571053-1cbf-4245-e9d4-568f77beca48"
      },
      "source": [
        "model.fit(train_X, train_y, epochs=20, verbose=1,\n",
        "         validation_split=0.1,\n",
        "         batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 357867 samples, validate on 39764 samples\n",
            "Epoch 1/20\n",
            "357867/357867 [==============================] - 72s 201us/sample - loss: 0.3956 - acc: 0.8066 - val_loss: 0.3111 - val_acc: 0.8519\n",
            "Epoch 2/20\n",
            "357867/357867 [==============================] - 72s 201us/sample - loss: 0.3538 - acc: 0.8311 - val_loss: 0.2687 - val_acc: 0.8740\n",
            "Epoch 3/20\n",
            "357867/357867 [==============================] - 73s 205us/sample - loss: 0.3480 - acc: 0.8358 - val_loss: 0.2735 - val_acc: 0.8751\n",
            "Epoch 4/20\n",
            "357867/357867 [==============================] - 72s 201us/sample - loss: 0.3429 - acc: 0.8386 - val_loss: 0.2631 - val_acc: 0.8783\n",
            "Epoch 5/20\n",
            "357867/357867 [==============================] - 72s 202us/sample - loss: 0.3438 - acc: 0.8390 - val_loss: 0.2700 - val_acc: 0.8783\n",
            "Epoch 6/20\n",
            "357867/357867 [==============================] - 73s 204us/sample - loss: 0.3504 - acc: 0.8355 - val_loss: 0.2721 - val_acc: 0.8749\n",
            "Epoch 7/20\n",
            "357867/357867 [==============================] - 72s 201us/sample - loss: 0.3396 - acc: 0.8414 - val_loss: 0.2612 - val_acc: 0.8808\n",
            "Epoch 8/20\n",
            "357867/357867 [==============================] - 72s 201us/sample - loss: 0.3486 - acc: 0.8349 - val_loss: 0.3026 - val_acc: 0.8647\n",
            "Epoch 9/20\n",
            "357867/357867 [==============================] - 73s 203us/sample - loss: 0.3657 - acc: 0.8234 - val_loss: 0.2776 - val_acc: 0.8678\n",
            "Epoch 10/20\n",
            "357867/357867 [==============================] - 73s 203us/sample - loss: 0.3658 - acc: 0.8236 - val_loss: 0.2749 - val_acc: 0.8714\n",
            "Epoch 11/20\n",
            "357867/357867 [==============================] - 72s 201us/sample - loss: 0.3628 - acc: 0.8249 - val_loss: 0.2760 - val_acc: 0.8727\n",
            "Epoch 12/20\n",
            "357867/357867 [==============================] - 72s 202us/sample - loss: 0.3578 - acc: 0.8287 - val_loss: 0.2666 - val_acc: 0.8765\n",
            "Epoch 13/20\n",
            "357867/357867 [==============================] - 72s 200us/sample - loss: 0.3662 - acc: 0.8233 - val_loss: 0.2649 - val_acc: 0.8776\n",
            "Epoch 14/20\n",
            "357867/357867 [==============================] - 72s 202us/sample - loss: 0.3622 - acc: 0.8237 - val_loss: 0.2716 - val_acc: 0.8711\n",
            "Epoch 15/20\n",
            "357867/357867 [==============================] - 72s 201us/sample - loss: 0.3598 - acc: 0.8237 - val_loss: 0.2683 - val_acc: 0.8741\n",
            "Epoch 16/20\n",
            "357867/357867 [==============================] - 72s 202us/sample - loss: 0.3677 - acc: 0.8189 - val_loss: 0.2651 - val_acc: 0.8781\n",
            "Epoch 17/20\n",
            "357867/357867 [==============================] - 72s 201us/sample - loss: 0.3656 - acc: 0.8213 - val_loss: 0.2657 - val_acc: 0.8703\n",
            "Epoch 18/20\n",
            "357867/357867 [==============================] - 73s 204us/sample - loss: 0.3693 - acc: 0.8183 - val_loss: 0.2756 - val_acc: 0.8718\n",
            "Epoch 19/20\n",
            "357867/357867 [==============================] - 72s 201us/sample - loss: 0.3716 - acc: 0.8159 - val_loss: 0.2722 - val_acc: 0.8764\n",
            "Epoch 20/20\n",
            "357867/357867 [==============================] - 71s 198us/sample - loss: 0.3706 - acc: 0.8168 - val_loss: 0.2778 - val_acc: 0.8667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f943e3a12b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBlQv2_BGQ15",
        "colab_type": "text"
      },
      "source": [
        "## Test our model\n",
        "\n",
        "We test our model on a random set of statements to see how the sentiment comes out from our model. The predictions return an array of [joy, anger] percentages for each statement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZrOcsamDx8-",
        "colab_type": "code",
        "colab": {},
        "outputId": "4d59ff42-8781-44ea-a51d-45bcbfa2f2b0"
      },
      "source": [
        "tweets = [\"I love the world\",\n",
        "          \"I hate the world\",\n",
        "          \"I'm not happy about riots\",\n",
        "          \"I like ice cream\"\n",
        "         ]\n",
        "\n",
        "tweet_docs = tkn.texts_to_sequences(tweets)\n",
        "tweet_padded_docs = pad_sequences(tweet_docs, maxlen=max_len, padding='post')\n",
        "\n",
        "model.predict(tweet_padded_docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5283357 , 0.4716643 ],\n",
              "       [0.21932708, 0.78067297],\n",
              "       [0.45187068, 0.5481293 ],\n",
              "       [0.6312392 , 0.3687608 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dJOB63JDx9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}